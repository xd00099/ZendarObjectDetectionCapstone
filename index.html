<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automatic Radar Labeling</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" integrity="sha384-iQ8OA2+Joomla.dy4x6IjJqfsqFqRe/j98TIDT61uYcrrNTt8Ov4y4j4L4eMAPKd8" crossorigin="anonymous">

    <script>
        $(document).ready(function(){
            $('a[href^="#"]').on('click', function (e) {
                e.preventDefault();

                var target = this.hash;
                var $target = $(target);

                $('html, body').stop().animate({
                    'scrollTop': $target.offset().top
                }, 900, 'swing', function () {
                    window.location.hash = target;
                });
            });
        });
    </script>
</head>
<body>
    <div class="overview-section"></div>
    <header>
        <nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top">
            <a class="navbar-brand" href="index.html">Automatic Radar Labeling</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="#overview">Overview</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#motivation">Motivation</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#results">Results</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#limitations">Limitations</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#contact">Contact</a>
                    </li>
                </ul>
            </div>
        </nav>
    </header>

    <main class="container mt-5 pt-5">
        <section class="white_bg" id="overview">
            <h1 style="text-align: center;">Revolutionizing Autonomous Driving Software For Safer Object Detection</h1>
            <p>Welcome to the project website! This project focuses on improving object detection and localization using radar and image data in complex environments. Here, you can explore the various aspects of our end-to-end pipeline, including coordinate transformation, YOLO object detection, DBSCAN clustering, and merging radar clusters with image labels.</p>
            
            <div class="overview-section">
                <h2 class="text-center mb-4">Overview</h2>
                <div class="row">
                    <div class="col-md-6 col-lg-3 mb-4">
                        <div class="card">
                            <div class="card-body">
                                <h5 class="card-title">Coordinate Transformation</h5>
                                <p class="card-text">Converting radar data from its native coordinate system to a coordinate system aligned with camera data.</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-3 mb-4">
                        <div class="card">
                            <div class="card-body">
                                <h5 class="card-title">YOLO Object Detection</h5>
                                <p class="card-text">A real-time object detection algorithm that simultaneously predicts object classes and bounding boxes.</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-3 mb-4">
                        <div class="card">
                            <div class="card-body">
                                <h5 class="card-title">DBSCAN Clustering</h5>
                                <p class="card-text">A density-based clustering algorithm used for unsupervised machine learning, grouping data points based on distance.</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-3 mb-4">
                        <div class="card">
                            <div class="card-body">
                                <h5 class="card-title">Merging Radar Clusters & Image Labels</h5>
                                <p class="card-text">Combining radar point data clusters with object labels generated by the YOLO algorithm for the image data.</p>
                            </div>
                        </div>
                    </div>
                </div>
                <p class="text-center">For more details about each step, please see the sections below.</p>
            </div>

            <figure style="justify-content: center; display: flex;">
                <img style="display: flex; max-width: 100%; height: auto;" src="assets/poster.png"/>
            </figure>
            
            
        </section>

        <section class="white_bg" id="motivation">
            <h2>Motivation & Benifits of Automatic Radar Labeling</h2>
            <ul>
            <li>    
                <strong>Data fusion validation:</strong> By labeling objects detected in both radar point cloud and image data, you can validate the accuracy and consistency of the data fusion process. This can help to ensure that the combined data is reliable and useful for various downstream tasks, such as object tracking, path planning, or decision-making.
            </li>
            <li>   
                <strong>Better understanding of object properties:</strong> Associating radar point cloud data with image-based object detections allows for a richer understanding of the properties of detected objects. For example, you can gain insight into an object's position, velocity, and distance (from radar data) and its appearance, shape, and texture (from image data). This can be especially useful for tasks such as object classification or behavior prediction.
            </li>
            <li>
                <strong>Improved object detection performance:</strong> By focusing on objects detectable by both radar and camera, you can improve the overall object detection performance of your system. The fusion of these two modalities can help to confirm and validate the presence of objects in the scene, leading to more accurate and reliable detection results. Additionally, it can help to reduce false positives and negatives.
            </li>
            <li>
                <strong>Enhanced safety and reliability:</strong> In autonomous driving and advanced driver assistance systems (ADAS), safety and reliability are paramount. By labeling radar point cloud data that is also detected by the camera, you can provide an additional layer of redundancy and validation for the object detection system. This can contribute to a safer and more reliable driving experience.
            </li>
            </ul>
        </section>
        <section class="white_bg" id="results">
            <h2>Pipeline & Results</h2>
            <h3>1. Coordinate Transformation</h3>
            <p>Coordinate transformation involves converting radar data from its native coordinate system (radar space) to a coordinate system that is aligned with the camera data (camera space). This process allows for the integration of information from multiple sensors to improve the accuracy of object detection and localization in complex environments.</p>
            <div style="justify-content: center;" class="row">
                <div class="col-lg-6 col-md-10 col-sm-10">
                    <img src="assets/point_cloud.png" alt="Coordinate Transformation Result" class="img-fluid">
                    <p style="text-align: center;">Radar in native 3D coordinate</p>
                </div>
                
            </div>

            <p style="text-align: center;">&#8595;</p>

            <div style="justify-content: center;" class="row">
            <div class="col-lg-6 col-md-10 col-sm-10">
                <img src="assets/vehicle.png" alt="Coordinate Transformation Result" class="img-fluid">
                <p style="text-align: center;">Projection to 3D vehicle coordinate</p>
            </div>
            </div>

            <p style="text-align: center;">&#8595;</p>

            <div class="row">
                <div class="col-lg-4 col-md-10 col-sm-10">
                    <img src="assets/coord_l.png" alt="Coordinate Transformation Result" class="img-fluid">
                    <p style="text-align: center;">Projection onto 2D left image</p>
                </div>
                <div class="col-lg-4 col-md-10 col-sm-10">
                    <img src="assets/coordinate_trans.png" alt="Coordinate Transformation Result" class="img-fluid">
                    <p style="text-align: center;">Projection onto 2D middle image</p>
                </div>
                <div class="col-lg-4 col-md-10 col-sm-10">
                    <img src="assets/coord_r.png" alt="Coordinate Transformation Result" class="img-fluid">
                    <p style="text-align: center;">Projection onto 2D right image</p>
                </div>
            </div>
        
        
            <h3>2. YOLOv3 Object Detection</h3>
            <p>YOLO (You Only Look Once) is a real-time object detection algorithm. It leverages a single neural network to simultaneously predict object classes and bounding boxes for those objects in input images. The algorithm is trained using a large dataset of labeled images and backpropagation to update the weights of the neural network.</p>
            <div class="row">
                <div class="col-lg-4 col-md-12 col-sm-12">
                    
                    <img src="assets/yolo_l.png" alt="YOLO Detection Result 1" class="img-fluid">
                    <p style="text-align: center;">Left Camera YOLO Results</p>
                </div>
                <div class="col-lg-4 col-md-12 col-sm-12">
                    
                    <img src="assets/yolo_mid.png" alt="YOLO Detection Result 2" class="img-fluid">
                    <p style="text-align: center;">Middle Camera YOLO Results</p>
                </div>
                <div class="col-lg-4 col-md-12 col-sm-12">
                    
                    <img src="assets/yolo_r.png" alt="YOLO Detection Result 3" class="img-fluid">
                    <p style="text-align: center;">Right Camera YOLO Results</p>
                </div>
            </div>
        
            <h3>3. DBSCAN Clustering</h3>
            <p>DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm used for unsupervised machine learning. It groups together data points that are close to each other in feature space and separates data points that are far away. The algorithm identifies clusters based on their distance from each other and recursively adds nearby points that meet the epsilon and minimum points criteria until no more points can be added to the cluster.</p>
            <img style="display: flex; max-width: 100%; height: auto;" src="assets/dbscan.png" alt="DBSCAN Clustering Result" class="img-fluid">
        
            <h3>4. Merging Radar Clusters and Image Labels</h3>
            <p>The final step of the pipeline is to combine the results generated by the clustering and labeling algorithm. Radar point data clusters obtained from the DBSCAN algorithm are merged with object labels generated by the YOLO algorithm for the image data. This combination is accomplished by utilizing the overlapping bounding boxes between the radar points and image labels as a means of matching the results.</p>
            <div class="row">
                <div class="col-lg-6 col-md-6 col-sm-6">
                    <h4 style="text-align: center;">Before Merge</h4>
                </div>
                <div class="col-lg-6 col-md-6 col-sm-6">
                    <h4 style="text-align: center;">After Merge</h4>
                </div>
                <div class="col-lg-6 col-md-6 col-sm-6">
                    
                    <img src="assets/label_l_before.png" alt="YOLO Detection Result 1" class="img-fluid">
                    <p style="text-align: center;">Left Camera Clustering Results</p>
                </div>
                <div class="col-lg-6 col-md-6 col-sm-6">
                    
                    <img src="assets/label_l.png" alt="YOLO Detection Result 1" class="img-fluid">
                    <p style="text-align: center;">Left Camera Labeling Results</p>
                </div>

                <div class="col-lg-6 col-md-6 col-sm-6">
                    
                    <img src="assets/label_m_before.png" alt="YOLO Detection Result 2" class="img-fluid">
                    <p style="text-align: center;">Middle Camera Clustering Results</p>
                </div>
                <div class="col-lg-6 col-md-6 col-sm-6">
                    
                    <img src="assets/label_m.png" alt="YOLO Detection Result 2" class="img-fluid">
                    <p style="text-align: center;">Middle Camera Labeling Results</p>
                </div>

                <div class="col-lg-6 col-md-6 col-sm-6">
                    
                    <img src="assets/label_r_before.png" alt="YOLO Detection Result 3" class="img-fluid">
                    <p style="text-align: center;">Right Camera Clustering Results</p>
                </div>
                <div class="col-lg-6 col-md-6 col-sm-6">
                    
                    <img src="assets/label_r.png" alt="YOLO Detection Result 3" class="img-fluid">
                    <p style="text-align: center;">Right Camera Labeling Results</p>
                </div>
            </div>

            <h3>5. Birds Eye View with Labeled Data</h3>
            <p>In the end, once we have radar data labeled in 3D, we are able to show the labeled point cloud relative to the vehicle's position.</p>
            <p>Below is an example of the visualization.</p>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12">
                    <img src="assets/pointcloud_labeled.png" alt="YOLO Detection Result 2" class="img-fluid">
                    <p style="text-align: center;">Point Cloud Labeled Bird Eye View</p>
                </div>
            </div>
            

            <h3>6. Demo Video</h3>
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/c_XfQxetSiY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
        </section>
            
            <section class="white_bg" id="limitations">
                <h2>Limitations</h2>
                <p>While our end-to-end pipeline has shown promising results in object detection and localization, it is important to acknowledge some limitations and potential areas for improvement:</p>
                <ul>
                    <li><strong>Sensor limitations:</strong> The accuracy of our system largely depends on the quality and resolution of the input data from radar and image sensors. Low-quality sensors or noisy data can negatively affect the performance of the pipeline.</li>
                    <li><strong>Algorithm limitations:</strong> The YOLO object detection algorithm and DBSCAN clustering algorithm have their inherent limitations. For instance, YOLO may struggle to detect small or partially occluded objects, and DBSCAN is sensitive to the choice of hyperparameters, which can impact clustering quality.</li>
                    <li><strong>Computational complexity:</strong> Real-time processing of radar and image data requires significant computational resources. The pipeline may experience performance issues on low-end hardware or when handling large datasets.</li>
                    <li><strong>Generalization:</strong> Our pipeline's performance on diverse and complex environments is yet to be fully evaluated. More extensive testing and validation are required to ensure the robustness of the system in a variety of real-world scenarios.</li>
                </ul>
                <p>In future iterations of the project, we plan to address these limitations by refining our algorithms, incorporating more advanced sensor technologies, and optimizing the pipeline for better computational efficiency. The preliminary results demonstrate the potential of our approach in improving object detection and localization, and we believe further development can lead to more accurate and robust systems for autonomous driving applications.</p>
            </section>

        </main>
</body>

<footer id="contact" class="bg-dark text-light py-3">
    <section class="container">
        <h2>Contact</h2>
        <p>If you have any questions or would like to learn more about the project, please feel free to get in touch:</p>
        <p>
            <strong>Project Lead:</strong> Du Xiang<br>
            <strong>Team Members:</strong> Du Xiang, Cheng-Kai Chen, Constantin Ghazi, Hendrick Chiche<br>
        </p>
        <ul class="list-unstyled list-inline">
            <li class="list-inline-item">
                <a href="https://www.linkedin.com/in/du-xiang" target="_blank" class="text-light">
                    <i class="fab fa-linkedin fa-2x"></i>
                </a>
            </li>
            <li class="list-inline-item">
                <a href="https://github.com/xd00099" target="_blank" class="text-light">
                    <i class="fab fa-github fa-2x"></i>
                </a>
            </li>
            <li class="list-inline-item">
                <a href="mailto:xd00099@berkeley.edu" class="text-light">
                    <i class="fas fa-envelope fa-2x"></i>
                </a>
            </li>
        </ul>
    </section>
    <div class="container text-center">
        <p class="mb-0">&copy; [2023] Du Xiang. All Rights Reserved.</p>
    </div>
</footer>
</html>